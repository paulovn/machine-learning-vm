#!/bin/bash
#
# Starts a Spark notebook
#
# chkconfig: 345 98 02
# description: Spark notebook process
#
### BEGIN INIT INFO
# Provides:          jupyter-notebook
# Short-Description: Jupyter notebook
# Default-Start:     3 4 5
# Default-Stop:      0 1 2 6
# Required-Start:    $syslog $remote_fs
# Required-Stop:     $syslog $remote_fs
# Should-Start:
# Should-Stop:
### END INIT INFO

# Source function library.                                     
. /lib/lsb/init-functions

# Slurp the Spark notebook configuration
if test -d /etc/sysconfig/jupyter-notebook; then
    CFGNAME=/etc/sysconfig/jupyter-notebook
else
    CFGNAME=/etc/jupyter/jupyter-notebook
fi
set -a
test -f ${CFGNAME} && . ${CFGNAME}
set +a
NOTEBOOK_USER=${NOTEBOOK_USER:-spark}
NOTEBOOK_SCRIPT="${NOTEBOOK_SCRIPT:-/opt/ipnb/bin/jupyter-notebook}"
NOTEBOOK_BASEDIR="${NOTEBOOK_BASEDIR:-/home/$NOTEBOOK_USER/IPNB}"
export LOGDIR=${LOGDIR:-/var/log/ipnb}

id ${NOTEBOOK_USER} >/dev/null 2>/dev/null || { echo "Error: user $NOTEBOOK_USER does not exist"; exit 1; }
test -f ${NOTEBOOK_SCRIPT} || { echo "Error: can't find script $NOTEBOOK_SCRIPT"; exit 1; }

DESC="Jupyter Notebook"
DAEMON="jupyter-notebook"
VARDIR="/run/ipnb"
PIDFILE="$VARDIR/$DAEMON.pid"
LOCKDIR="/var/lock/subsys"
LOCKFILE="$LOCKDIR/$DAEMON"
IDFILE="$VARDIR/pyspark-ipnb"

RETVAL_SUCCESS=0

STATUS_RUNNING=0
STATUS_DEAD=1
STATUS_DEAD_AND_LOCK=2
STATUS_NOT_RUNNING=3
STATUS_OTHER_ERROR=102

RETVAL=0
SLEEP_TIME=5
PROC_NAME=$(basename $NOTEBOOK_SCRIPT)

EXEC_PATH=$NOTEBOOK_SCRIPT
EXEC_DIR=""
DAEMON_FLAGS=""

# Ensure directories & files exist
for d in "$LOGDIR"
do
    [ -d "$d" ] || install -d -m 0755 -o $NOTEBOOK_USER -g $NOTEBOOK_USER "$d" 1>/dev/null 2>&1 || :
done
for d in "$VARDIR" "$LOCKDIR"
do
    [ -d "$d" ] || install -d -m 0755 "$d" 1>/dev/null 2>&1 || :
done
test -f $IDFILE || { echo 0 > $IDFILE; chown $NOTEBOOK_USER.$NOTEBOOK_USER $IDFILE; }


# -----------------------------------------------------------------------

start() {
    [ -x $EXE_FILE ] || exit $ERROR_PROGRAM_NOT_INSTALLED
    log_success_msg "Starting $DESC (${DAEMON}): "

    checkstatusofproc
    status=$?
    if [ "$status" -eq "$STATUS_RUNNING" ]; then
        log_success_msg "${DESC} is running"
        exit 0
    fi

    LOG_FILE=${LOGDIR}/${DAEMON}.out
    test -f $LOG_FILE || { touch $LOG_FILE; chown $NOTEBOOK_USER.$NOTEBOOK_USER $LOG_FILE; }

    THISDIR=$(dirname "$0")
    runuser $NOTEBOOK_USER -c "echo '************ Start on $(date)' >> ${LOG_FILE}"
    runuser $NOTEBOOK_USER -l -s /bin/bash  -c "nohup env NOTEBOOK_BASEDIR=$NOTEBOOK_BASEDIR $THISDIR/jupyter-notebook-wrapper $NOTEBOOK_SCRIPT >>$LOG_FILE 2>&1 &"' echo $! ' > $PIDFILE

    sleep 3

    checkstatusofproc
    RETVAL=$?
    [ $RETVAL -eq $STATUS_RUNNING ] && touch $LOCKFILE
    return $RETVAL
}


stop() {
    log_success_msg "Stopping $DESC (${DAEMON}): "
    # start-stop-daemon uses command name, which has a 15-char limit
    killproc -p $PIDFILE jupyter-noteboo
    RETVAL=$?

    [ $RETVAL -eq $RETVAL_SUCCESS ] && rm -f $LOCKFILE $PIDFILE
    return $RETVAL
}


restart() {
  stop
  start
}


checkstatusofproc(){
  pidofproc -p $PIDFILE $PROC_NAME > /dev/null
}


checkstatus(){
  checkstatusofproc
  status=$?

  case "$status" in
    $STATUS_RUNNING)
      log_success_msg "${DESC} is running"
      ;;
    $STATUS_DEAD)
      log_failure_msg "${DESC} is dead and pid file exists"
      ;;
    $STATUS_DEAD_AND_LOCK)
      log_failure_msg "${DESC} is dead and lock file exists"
      ;;
    $STATUS_NOT_RUNNING)
      log_failure_msg "${DESC} is not running"
      ;;
    *)
      log_failure_msg "${DESC} status is unknown"
      ;;
  esac
  return $status
}


condrestart(){
  [ -e $LOCKFILE ] && restart || :
}


check_for_root() {
  if [ $(id -ur) -ne 0 ]; then
    echo 'Error: root user required'
    echo
    exit 1
  fi
}


# -----------------------------------------------------------------------

set_mode()
{
    MODE=$1
    check_for_root
    test -f "/opt/spark/current/conf/spark-env.sh.$MODE" || { log_failure_msg "Error: config for $MODE missing. Probably needs set-addr"; return 1; }
    #test -f "${CFGNAME}.$MODE" || { log_failure_msg "can't find Spark config ${CFGNAME}.$MODE"; return 1; }
    checkstatusofproc && RUNNING=1
    test "$RUNNING" && { stop || return 1; }
    #echo "$MODE" > ${CFGNAME}
    (cd /opt/spark/current/conf; \
	rm -f spark-env.sh spark-defaults.conf; \
	ln -s spark-env.sh.$MODE spark-env.sh; \
	ln -s spark-defaults.conf.$MODE spark-defaults.conf) 
    log_success_msg "Configured Spark for mode: $MODE "
    test "$RUNNING" && { start; return $?; }
    return 0
}


set_addr()
{
    CONF=/opt/spark/current/conf/
    MODE="$1"
    test -f "${CONF}tpl/spark-defaults.conf.$MODE.tpl" || { echo "can't find Spark config template for ${MODE}"; exit 1; }
    MASTER_IP="$2"
    NAMENODE_IP="$3"
    HISTORY_SERVER="$4"
    test "$NAMENODE_IP" || NAMENODE_IP=$MASTER_IP
    case "$NAMENODE_IP" in
	hdfs*) ;;
	*)  EVENTLOG_DIR="hdfs://$NAMENODE_IP:8020/user/spark/applicationHistory";;
    esac
    case "$HISTORY_SERVER" in
	*:*);;
	'') HISTORY_SERVER=${MASTER_IP}:18080;;
	*) HISTORY_SERVER=${HISTORY_SERVER}:18080;;
    esac
    # Modify Spark config accordingly
    for f in spark-defaults.conf spark-env.sh
    do
	sed -e "s@{HOSTNAME-MASTER}@$MASTER_IP@" \
	    -e "s@{HOSTNAME-NAMENODE}@$NAMENODE_IP@" \
	    -e "s@{HOSTNAME-SPARK-HS}@$HISTORY_SERVER@" \
	    -e "s@{DIR-EVENTLOG}@$EVENTLOG_DIR@" \
	    ${CONF}tpl/$f.$MODE.tpl > ${CONF}$f.$MODE
    done
    # If in YARN mode, update also Hadoop/Yarn config
    if [ "$MODE" = "yarn" ] ;then
	sed "s@{HOSTNAME-YARN-RM}@$MASTER_IP@" ${CONF}tpl/yarn-site.xml.tpl > ${CONF}hadoop/yarn-site.xml 
	sed "s@{HOSTNAME-NAMENODE}@$NAMENODE_IP@" ${CONF}tpl/core-site.xml.tpl > ${CONF}hadoop/core-site.xml 
    fi
}


# -----------------------------------------------------------------------

usage() {
    echo $"Usage: $0 {start|stop|status|restart|try-restart|condrestart}"
    echo $"       $0 set-mode (local | standalone | yarn)"
    echo $"       $0 set-addr (standalone|yarn) <master-addr> [<namenode-addr> [<hserver-addr>]]"
    exit 1
}


service() {
  case "$1" in
    start)
      check_for_root
      start
      ;;
    stop)
      check_for_root
      stop
      ;;
    status)
      checkstatus
      RETVAL=$?
      ;;
    restart)
      check_for_root
      restart
      ;;
    condrestart|try-restart)
      check_for_root
      condrestart
      ;;
    set-mode)
      test "$2" = "local" -o "$2" = "yarn" -o "$2" = "standalone" || usage
      check_for_root
      set_mode $2
      RETVAL=$?
      ;;
    set-addr)
      check_for_root
      shift
      test "$1" = "yarn" -o "$1" = "standalone" || usage
      set_addr $@
      RETVAL=$?
      ;;
    *)
      usage
      ;;
  esac
}

service "$@"

exit $RETVAL
