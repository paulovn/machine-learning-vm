v. 1.9.6
 * Spark is 2.1.0
 * based on CentOS 7.3
 * IPython 5.3.0
 * R 3.3.2
 * use OpenJDK 8 instead of Oracle Java
 * no Theano/Keras installation (left to child boxes),
 * fixes in manager script
 * custom build of Spark, including native BLAS bindings
 * sparklyr installed from github
 * custom Toree build
 
v. 1.9.3
 * Spark is 2.0.2
 * added sparklyr
 * notebook daemon started as Systemd service
 * theanorc modified for explicit linking to openblas

v. 1.9.2
 * Spark is 2.0.1
 * Uses OpenJDK 1.8 instead of Oracle Java 8
 * R installation refactored to avoid pulling in Java 1.7

v. 1.9.1
 * Spark is 2.0.0
 * R is 3.3.1
 * Based on CentOS 7.2 (w/ Python 2.7.5)
 * No Python SCL installation (uses system Python 2.7)
 * IPython 5.1.0
 * Removed Spark add-ons (csv is built-in, graphframes can be downloaded on
   the fly)

v. 1.0.0

v. 0.9.13
 * Spark updated to 1.6.2
 * Added graphviz Python package
 * Added a system theanorc file
 * Install openblas
 * Updated to the most recent available versions of Python & R packages
 * Reduced Spark log levels

v. 0.9.12
 * R updated to 3.3.0
 * Python updated to 2.7.8
 * bugfix in notebook service script
 * Updated Toree kernel

v. 0.9.11
 * bugfixes

v. 0.9.10
 * Spark is 1.6.1
 * Spark Kernel changed to Toree
 * Added additional Python packages (Theano, Keras, Openpyxl, xlrd, h5py,
   tables)
 * R updated to 3.2.3
 * Added additional R packages: caret
 * Configured to allow 2 Python kernal: a base 2.7 and a Pyspark kernel
 * Added a couple of additional notebook extensions

v. 0.9.8
 * added a missing dependency for spark-csv
 * config option for extra path to include spark-csv (commented out)

v. 0.9.7

 * Spark is 1.6.0
 * Added configuration of Spark mode + cluster addr via script
 * Default network mode is bridged mode, to enable access to remote execution
 * Added additional jars (Kafka Spark Streaming, Spark CSV)

v. 0.9.5

 * Spark updated to 1.5.2
 * Add a slightly modified Jupyter icon
 * Updated Java 8 (to JDK 8u65)
 * Added more Pyhon libraries to virtualenv (statmodels, mpld3, seaborn, hdfs)
 * Added Spark/Scala notebook kernel, for Scala 2.10.5
     * added scala icon
 * Notebook extensions
     * modified ToC nbextension (suppress numbers in already numbered headings)
     * add search-replace nbextension
     * add toggle-headers nbextension
 * bugfix: added chown to spark log file in daemon script


v. 0.9.4

 * Start with a Centos 6.7 box
 * Download all needed support packages: Java 8, R, Python 2.7
 * Create a Python virtualenv & download Python libraries for scientific computing, inc. Jupyter notebooks
 * Add some R packages, including IRkernel
 * Download & install Spark 1.5.0
 * Download & install Scala 2.10
 * Install a few other goodies

The resulting Spark installation is pre-configured, but not yet started 
in the VM.
